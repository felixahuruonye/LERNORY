// OpenAI integration blueprint reference: javascript_openai
import OpenAI from "openai";
import fs from "fs";

// Initialize OpenAI client (primary)
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Initialize OpenRouter client (fallback) - NOT used for audio/whisper
const openrouter = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY,
  baseURL: "https://openrouter.ai/api/v1",
});

// Helper function to check if error is quota-related
function isQuotaError(error: any): boolean {
  return (
    error?.status === 429 ||
    error?.code === "insufficient_quota" ||
    error?.code === "rate_limit_exceeded" ||
    error?.message?.includes("quota") ||
    error?.message?.includes("exceeded")
  );
}

// Helper function to try OpenAI first, fallback to OpenRouter, then Gemini for chat
async function tryWithFallback<T>(
  primaryFn: () => Promise<T>,
  fallbackFn?: () => Promise<T>,
  geminiFunction?: () => Promise<T>,
  isAudioFunction?: boolean
): Promise<T> {
  try {
    console.log("Trying primary API (OpenAI)...");
    return await primaryFn();
  } catch (primaryError) {
    console.error("Primary API (OpenAI) failed:", primaryError instanceof Error ? primaryError.message : primaryError);
    
    // For audio functions (Whisper), don't try other APIs since they don't support audio
    if (isAudioFunction) {
      throw primaryError;
    }
    
    // Try fallback (OpenRouter)
    if (fallbackFn) {
      try {
        console.log("Switching to OpenRouter API (fallback)...");
        return await fallbackFn();
      } catch (fallbackError) {
        console.error("OpenRouter API also failed:", fallbackError instanceof Error ? fallbackError.message : fallbackError);
        
        // Try Gemini as final fallback
        if (geminiFunction) {
          try {
            console.log("Switching to Gemini API (final fallback)...");
            return await geminiFunction();
          } catch (geminiError) {
            console.error("Gemini API also failed:", geminiError instanceof Error ? geminiError.message : geminiError);
            throw geminiError;
          }
        }
        throw fallbackError;
      }
    }
    throw primaryError;
  }
}

export async function chatWithAI(messages: Array<{role: string; content: string}>): Promise<string> {
  // Detect if this is the first message
  const isFirstMessage = messages.length === 1;
  
  // Detect language request
  const lastMessage = messages[messages.length - 1]?.content || "";
  const languageMatch = lastMessage.match(/(?:speak|respond|answer|teach)\s+(?:me\s+)?(?:in|with)?\s+([A-Za-z\s]+?)(?:\.|$|!|\?)/i);
  const requestedLanguage = languageMatch ? languageMatch[1].toLowerCase().trim() : null;
  
  // Detect learning mode request
  const modeMatch = lastMessage.match(/\[MODE:\s*(learning|exam|revision|quick|eli5|advanced|practice)\]/i);
  const requestedMode = modeMatch ? modeMatch[1].toLowerCase() : 'learning';

  // Add system prompt
  const systemPrompt = `You are LEARNORY, the world's most comprehensive AI learning platform. You seamlessly operate as 9 integrated roles and 7 learning modes.

ðŸŽ“ YOUR 9 INTEGRATED ROLES:
1. DIGITAL TUTOR - Expert explanations with examples, analogies, real-world relevance
2. EXAM PREP SYSTEM - MCQs, essays, past papers, timed practice, performance tracking
3. COURSE GENERATOR - Creates complete courses: outline â†’ topics â†’ lessons â†’ practice â†’ assignments
4. STUDY PLANNER - Generates custom study schedules based on exam dates, weak areas, available time
5. QUESTION SOLVER - Solves ANY problem: equations, word problems, code, essays with full working
6. CAREER ADVISOR - University guidance, job skills, salary info, career paths, admission requirements
7. SUMMARIZER - Text to summaries (short/medium/long), outlines, flashcards, mind-maps
8. CODE DEBUGGER - Debugs any language, explains errors, fixes code, adds features, generates components
9. MEMORY-BASED LEARNING ASSISTANT - Tracks progress, weak topics, learning style, provides personalized guidance

ðŸ“š COMPREHENSIVE SUBJECT MASTERY:
Mathematics, Physics, Chemistry, Biology, English, Literature, Computer Science, Programming, Economics, Government, History, Business, Accounting, Commerce, Civic, Data Science, AI, Web Dev, Cloud, Networking, + ALL other school/tech subjects

ðŸŽ¯ YOUR 7 LEARNING MODES (Current: ${requestedMode.toUpperCase()}):
1. LEARNING MODE - Long detailed explanations, step-by-step breakdowns, multiple examples
2. EXAM MODE - Strict format, no hints, realistic exam conditions, formal tone
3. REVISION MODE - Concise summaries, key points only, flashcard style
4. QUICK ANSWER MODE - Brief direct answers, formulas, definitions only
5. ELI5 MODE - Extremely simple language, analogies, 5-year-old understanding
6. ADVANCED MODE - Full technical depth, advanced concepts, research-level details
7. PRACTICE MODE - Generate endless practice questions with solutions

ðŸŒŸ YOUR CAPABILITIES:

ðŸ“ FOR COURSE GENERATION (when user says "Generate course on [topic]"):
Create structured course with:
â€¢ Full outline with topics
â€¢ Topic-by-topic breakdown
â€¢ Detailed lesson notes
â€¢ Practice questions per topic
â€¢ Real-world applications
â€¢ Weekly schedule
â€¢ Assignments

â“ FOR QUESTION SOLVING:
â€¢ Show FULL working/steps
â€¢ Explain your reasoning
â€¢ Provide alternative methods
â€¢ Generate 3 similar practice questions
â€¢ Highlight common mistakes
â€¢ Provide shortcuts/formulas

ðŸ« FOR EXAM PREP (WAEC, NECO, JAMB, University):
â€¢ Generate MCQs, True/False, Short answer, Essays
â€¢ Mark answers with explanations
â€¢ Track performance by topic
â€¢ Identify weak areas
â€¢ Provide targeted practice

ðŸ“‘ FOR STUDY PLANNING (when user says "Create study plan"):
Ask for:
â€¢ Exam type & deadline
â€¢ Subjects & weak areas
â€¢ Hours available per day
Then generate:
â€¢ Complete daily schedule
â€¢ Topic progression
â€¢ Practice schedule
â€¢ Milestone tracking

ðŸŽ¯ FOR CODE DEBUGGING/PROGRAMMING:
Support ALL languages: Python, JavaScript, Java, C++, Go, Rust, PHP, etc.
â€¢ Debug & explain errors
â€¢ Rewrite/optimize code
â€¢ Add missing features
â€¢ Generate components/routes
â€¢ Convert between languages
â€¢ Generate API documentation

ðŸŒ LANGUAGE & CULTURE MASTERY:
â€¢ Nigerian Pidgin, Yoruba, Igbo, Hausa, + global languages
â€¢ Nigerian slangs: "Wetin", "Abi", "Juwon", "Enh enh", etc.
${requestedLanguage ? `â€¢ USER REQUESTED: Respond in ${requestedLanguage}\n` : ''}
ðŸŽ¨ STICKER SYSTEM (use context-appropriate sticker at response start):
ðŸŽ“ ðŸ§® ðŸ”¬ ðŸ“š ðŸ’¡ ðŸŽ¯ ðŸŽ‰ ðŸ˜Š ðŸ§  ðŸ’» ðŸŒ ðŸŽ¨ â“ âœ…

MODE-SPECIFIC BEHAVIOR (Current: ${requestedMode.toUpperCase()}):
- LEARNING: Comprehensive explanations, multiple examples, deep understanding
- EXAM: Strict format, timed thinking, realistic conditions, no help
- REVISION: Ultra-concise, key points only, perfect for cramming
- QUICK: Instant answers, formulas only, definitions
- ELI5: Simplest language ever, fun analogies, no jargon
- ADVANCED: Technical depth, research-level, complex concepts
- PRACTICE: Endless questions with solutions, difficulty progression

PERSONALITY:
â€¢ Friendly, supportive, intelligent, motivational
â€¢ Use Nigerian slangs naturally (not when user is very serious)
â€¢ Clear structured explanations
â€¢ Detect weaknesses automatically
â€¢ Adapt to user's learning pace
â€¢ Ask if user wants more practice
â€¢ Make learning engaging and fun
${isFirstMessage ? 'â€¢ INTRODUCTION: Introduce as LEARNORY, your comprehensive learning partner\n' : ''}

CRITICAL RULES:
âœ“ Always show formulas in text format (e.g., y = mx + b)
âœ“ Always explain EVERY step in problem solving
âœ“ Always provide working/reasoning
âœ“ Always offer alternatives
âœ“ Always track mentioned weak topics
âœ“ Always adapt to current mode (${requestedMode.toUpperCase()})
âœ“ Always be honest about what you're doing (tutoring, planning, coding, etc.)
âœ“ ALWAYS start with relevant sticker when appropriate

You are LEARNORY - Nigeria's most intelligent, comprehensive learning platform designed to make education accessible, engaging, and effective for everyone.`;

  const messagesWithSystem = messages[0]?.role !== "system" 
    ? [
        {
          role: "system",
          content: systemPrompt
        },
        ...messages
      ]
    : messages;

  // Import Gemini function for fallback
  const { chatWithGemini } = await import("./gemini");

  return tryWithFallback(
    () => openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: messagesWithSystem as any,
      max_tokens: 1500,
      temperature: 0.8,
    }).then(response => response.choices[0].message.content || ""),
    
    () => openrouter.chat.completions.create({
      model: "meta-llama/llama-3-8b-instruct",
      messages: messagesWithSystem as any,
      max_tokens: 1200,
      temperature: 0.8,
    }).then(response => response.choices[0].message.content || ""),
    
    () => chatWithGemini(messages)
  );
}

export async function generateLesson(transcriptText: string): Promise<any> {
  return tryWithFallback(
    () => openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: "Create a lesson from the transcript. Respond with: TITLE: [title]\nOBJECTIVES: [list]\nKEY_POINTS: [list]\nSUMMARY: [summary]",
        },
        {
          role: "user",
          content: `Convert this transcript into a lesson:\n\n${transcriptText.slice(0, 1000)}`,
        },
      ],
      max_tokens: 800,
    }).then(response => {
      const text = response.choices[0].message.content || "";
      const titleMatch = text.match(/TITLE:\s*(.+?)(?:\n|$)/);
      const objMatch = text.match(/OBJECTIVES:\s*(.+?)(?:\nKEY|$)/);
      const keyMatch = text.match(/KEY_POINTS:\s*(.+?)(?:\nSUMMARY|$)/);
      const sumMatch = text.match(/SUMMARY:\s*([\s\S]*?)$/);
      
      return {
        title: titleMatch ? titleMatch[1].trim() : "Untitled Lesson",
        objectives: objMatch ? objMatch[1].split(',').map(o => o.trim()) : [],
        keyPoints: keyMatch ? keyMatch[1].split(',').map(k => k.trim()) : [],
        summary: sumMatch ? sumMatch[1].trim() : "",
      };
    }),
    
    () => openrouter.chat.completions.create({
      model: "meta-llama/llama-3-8b-instruct",
      messages: [
        {
          role: "system",
          content: "Create a lesson from the transcript. Respond with: TITLE: [title]\nOBJECTIVES: [list]\nKEY_POINTS: [list]\nSUMMARY: [summary]",
        },
        {
          role: "user",
          content: `Convert this transcript into a lesson:\n\n${transcriptText.slice(0, 800)}`,
        },
      ],
      max_tokens: 600,
    }).then(response => {
      const text = response.choices[0].message.content || "";
      const titleMatch = text.match(/TITLE:\s*(.+?)(?:\n|$)/);
      const objMatch = text.match(/OBJECTIVES:\s*(.+?)(?:\nKEY|$)/);
      const keyMatch = text.match(/KEY_POINTS:\s*(.+?)(?:\nSUMMARY|$)/);
      const sumMatch = text.match(/SUMMARY:\s*([\s\S]*?)$/);
      
      return {
        title: titleMatch ? titleMatch[1].trim() : "Untitled Lesson",
        objectives: objMatch ? objMatch[1].split(',').map(o => o.trim()) : [],
        keyPoints: keyMatch ? keyMatch[1].split(',').map(k => k.trim()) : [],
        summary: sumMatch ? sumMatch[1].trim() : "",
      };
    })
  );
}

export async function generateSyllabus(topic: string): Promise<any> {
  return tryWithFallback(
    () => openai.chat.completions.create({
      model: "gpt-5",
      messages: [
        {
          role: "system",
          content: "You are an expert curriculum designer. Generate a comprehensive course syllabus with modules and lessons. Respond with JSON in this format: { 'title': string, 'description': string, 'modules': [{ 'title': string, 'lessons': [{ 'title': string, 'description': string, 'duration': string }] }] }",
        },
        {
          role: "user",
          content: `Create a comprehensive course syllabus for: ${topic}`,
        },
      ],
      response_format: { type: "json_object" },
    }).then(response => JSON.parse(response.choices[0].message.content || "{}")),
    
    () => openrouter.chat.completions.create({
      model: "openai/gpt-4-turbo",
      messages: [
        {
          role: "system",
          content: "You are an expert curriculum designer. Generate a comprehensive course syllabus with modules and lessons. Respond with JSON in this format: { 'title': string, 'description': string, 'modules': [{ 'title': string, 'lessons': [{ 'title': string, 'description': string, 'duration': string }] }] }",
        },
        {
          role: "user",
          content: `Create a comprehensive course syllabus for: ${topic}`,
        },
      ],
    }).then(response => JSON.parse(response.choices[0].message.content || "{}"))
  );
}

export async function gradeQuiz(answers: any, rubric: any): Promise<any> {
  return tryWithFallback(
    () => openai.chat.completions.create({
      model: "gpt-5",
      messages: [
        {
          role: "system",
          content: "You are an expert grader. Evaluate the student's answers according to the rubric and provide detailed feedback. Respond with JSON in this format: { 'score': number, 'totalPoints': number, 'feedback': [{ 'question': number, 'points': number, 'comment': string }] }",
        },
        {
          role: "user",
          content: `Grade these answers:\n\nAnswers: ${JSON.stringify(answers)}\n\nRubric: ${JSON.stringify(rubric)}`,
        },
      ],
      response_format: { type: "json_object" },
    }).then(response => JSON.parse(response.choices[0].message.content || "{}")),
    
    () => openrouter.chat.completions.create({
      model: "openai/gpt-4-turbo",
      messages: [
        {
          role: "system",
          content: "You are an expert grader. Evaluate the student's answers according to the rubric and provide detailed feedback. Respond with JSON in this format: { 'score': number, 'totalPoints': number, 'feedback': [{ 'question': number, 'points': number, 'comment': string }] }",
        },
        {
          role: "user",
          content: `Grade these answers:\n\nAnswers: ${JSON.stringify(answers)}\n\nRubric: ${JSON.stringify(rubric)}`,
        },
      ],
    }).then(response => JSON.parse(response.choices[0].message.content || "{}"))
  );
}

export async function transcribeAudio(audioFilePath: string): Promise<{ text: string, duration: number }> {
  try {
    // OpenAI Whisper only - no fallback for audio
    const audioReadStream = fs.createReadStream(audioFilePath);
    const transcription = await openai.audio.transcriptions.create({
      file: audioReadStream,
      model: "whisper-1",
    });
    
    return {
      text: transcription.text,
      duration: 0,
    };
  } catch (error: any) {
    console.error("Transcription error with OpenAI:", error);
    
    // If OpenAI quota is exceeded, return a helpful message
    if (isQuotaError(error)) {
      return {
        text: "[Transcription unavailable - OpenAI quota exceeded. Please recharge your OpenAI account at https://platform.openai.com/account/billing/overview]",
        duration: 0,
      };
    }
    
    throw error;
  }
}

export async function generateSpeech(text: string): Promise<Buffer> {
  return tryWithFallback(
    () => openai.audio.speech.create({
      model: "tts-1",
      voice: "alloy",
      input: text,
    }).then(response => Buffer.from(response as any)),
    
    // No OpenRouter speech support
    undefined,
    false
  );
}

export async function summarizeText(text: string, length: 'short' | 'medium' | 'long' = 'medium'): Promise<string> {
  const lengthInstructions = {
    short: "in 2-3 sentences",
    medium: "in 1-2 paragraphs",
    long: "in detail with multiple paragraphs"
  };

  const prompt = `Please summarize the following text ${lengthInstructions[length]}:\n\n${text}`;

  return tryWithFallback(
    () => openai.chat.completions.create({
      model: "gpt-5",
      messages: [{ role: "user", content: prompt }],
    }).then(response => response.choices[0].message.content || ""),
    
    () => openrouter.chat.completions.create({
      model: "openai/gpt-4-turbo",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 2000,
    }).then(response => response.choices[0].message.content || "")
  );
}

export async function generateFlashcards(text: string): Promise<any> {
  return tryWithFallback(
    () => openai.chat.completions.create({
      model: "gpt-5",
      messages: [
        {
          role: "system",
          content: "You are an expert at creating study flashcards. Generate flashcards from the provided text. Respond with JSON in this format: { 'flashcards': [{ 'front': string, 'back': string }] }",
        },
        {
          role: "user",
          content: `Generate flashcards from this text:\n\n${text}`,
        },
      ],
      response_format: { type: "json_object" },
    }).then(response => JSON.parse(response.choices[0].message.content || "{}")),
    
    () => openrouter.chat.completions.create({
      model: "openai/gpt-4-turbo",
      messages: [
        {
          role: "system",
          content: "You are an expert at creating study flashcards. Generate flashcards from the provided text. Respond with JSON in this format: { 'flashcards': [{ 'front': string, 'back': string }] }",
        },
        {
          role: "user",
          content: `Generate flashcards from this text:\n\n${text}`,
        },
      ],
      max_tokens: 2000,
    }).then(response => JSON.parse(response.choices[0].message.content || "{}"))
  );
}
